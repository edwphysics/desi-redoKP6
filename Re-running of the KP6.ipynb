{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59b3a7bf-d974-4497-a3a3-55471d6f27c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python packages\n",
    "\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af822f2-f122-4ca5-8096-9c5fc01d7b8d",
   "metadata": {},
   "source": [
    "# Importing Re-gunning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a6f27-04c1-4cfa-9964-4b195c8361af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to the folder located in your user where the data is located\n",
    "redo_path = '/pscratch/sd/p/physedw/redoKP6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d59b0a-7c5d-444d-a785-ac6bb97603eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to store data obtained from deltas\n",
    "deltas = {\n",
    "    'ciii': fits.open(f'{redo_path}/deltas/delta-ciii/Log/delta_attributes.fits.gz'),\n",
    "    'lya': fits.open(f'{redo_path}/deltas/delta-lya/Log/delta_attributes.fits.gz'),\n",
    "    'lyb': fits.open(f'{redo_path}/deltas/delta-lyb/Log/delta_attributes.fits.gz')\n",
    "}\n",
    "\n",
    "# Print basic information to verify that the files are imported\n",
    "print(\"=== BASIC INFORMATION ON DELTAS ===\")\n",
    "print(f\"{len(deltas)} correlation functions were loaded:\")\n",
    "print()\n",
    "\n",
    "for name, hdul in deltas.items():\n",
    "    print(f\"ðŸ“Š {name.upper()}:\")\n",
    "    print(\"-\" * 40)\n",
    "    hdul.info()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ac10a-3def-4786-bfbe-759c464cd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to store the obtained correlation functions\n",
    "correlation_functions = {\n",
    "    'lyalya': fits.open(f'{redo_path}/correlations/correlation-lyalya/cf_lya_x_lya_exp.fits'),\n",
    "    'lyalyb': fits.open(f'{redo_path}/correlations/correlation-lyalyb/cf_lya_x_lyb_exp.fits'),\n",
    "    'qsolya': fits.open(f'{redo_path}/correlations/correlation-qsolya/cf_qso_x_lya_exp.fits'),\n",
    "    'qsolyb': fits.open(f'{redo_path}/correlations/correlation-qsolyb/cf_qso_x_lyb_exp.fits')\n",
    "}\n",
    "\n",
    "# Print basic information to verify that the files are imported\n",
    "print(\"=== BASIC INFORMATION ON CORRELATION FUNCTIONS ===\")\n",
    "print(f\"{len(correlation_functions)} correlation functions were loaded:\")\n",
    "print()\n",
    "\n",
    "for name, hdul in correlation_functions.items():\n",
    "    print(f\"ðŸ“Š {name.upper()}:\")\n",
    "    print(\"-\" * 40)\n",
    "    hdul.info()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d5f21-68d3-4502-9bbc-ec5cf785157f",
   "metadata": {},
   "source": [
    "# Importing Baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06670b-5c0e-4fc6-9dcb-738f13f90415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to the folder located of BASELINE KP6 data\n",
    "baseline_path = '/global/cfs/cdirs/desi/science/lya/y1-kp6/iron-baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313f21d-a9e4-4d9e-a9c2-fe718456f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to store data obtained from BASELINE deltas\n",
    "deltasKP6 = {\n",
    "    'ciii': fits.open(f'{baseline_path}/deltas/delta-ciii-0-0/Log/delta_attributes.fits.gz'),\n",
    "    'lya': fits.open(f'{baseline_path}/deltas/delta-lya-0-0/Log/delta_attributes.fits.gz'),\n",
    "    'lyb': fits.open(f'{baseline_path}/deltas/delta-lyb-0-0/Log/delta_attributes.fits.gz')\n",
    "}\n",
    "\n",
    "# Print basic information to verify that the files are imported\n",
    "print(\"=== BASIC INFORMATION ON DELTAS ===\")\n",
    "print(f\"{len(deltasKP6)} correlation functions were loaded:\")\n",
    "print()\n",
    "\n",
    "for name, hdul in deltasKP6.items():\n",
    "    print(f\"ðŸ“Š {name.upper()}:\")\n",
    "    print(\"-\" * 40)\n",
    "    hdul.info()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02e6f1-6dc4-48cf-a011-aaedcbd87a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to store the BASELINE correlation functions\n",
    "correlation_functions_baseline = {\n",
    "    'lyalya': fits.open(f'{baseline_path}/correlations/correlation-lyalya-0-0-0/cf_lya_x_lya_exp.fits'),\n",
    "    'lyalyb': fits.open(f'{baseline_path}/correlations/correlation-lyalyb-0-0-0/cf_lya_x_lyb_exp.fits'),\n",
    "    'qsolya': fits.open(f'{baseline_path}/correlations/correlation-qsolya-0-0-0/cf_qso_x_lya_exp.fits'),\n",
    "    'qsolyb': fits.open(f'{baseline_path}/correlations/correlation-qsolyb-0-0-0/cf_qso_x_lyb_exp.fits')\n",
    "}\n",
    "\n",
    "# Print basic information to verify that the files are imported\n",
    "print(\"=== BASIC INFORMATION ON BASELINE CORRELATION FUNCTIONS ===\")\n",
    "print(f\"{len(correlation_functions_baseline)} baseline correlation functions were loaded:\")\n",
    "print()\n",
    "\n",
    "for name, hdul in correlation_functions_baseline.items():\n",
    "    print(f\"ðŸ“Š BASELINE {name.upper()}:\")\n",
    "    print(\"-\" * 40)\n",
    "    hdul.info()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f172dc-f522-41bb-8cda-9c6d1b6cce9a",
   "metadata": {},
   "source": [
    "# Re-running and Baseline deltas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5b2935-746e-46e4-b046-8d5e8a90cb4c",
   "metadata": {},
   "source": [
    "## Exploring Re-running deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc97ef-9139-4a31-b944-3d2841c033a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the contents of the lya .fits\n",
    "print('--- PRIMARY HEADER ---\\n')\n",
    "for key, value in deltas['lya'][0].header.items():\n",
    "        print(f\"{key:12} : {value}\")\n",
    "\n",
    "for i in range(len(deltas['lya'])):\n",
    "    hdu = deltas['lya'][i]\n",
    "    print(f\"\\n--- {hdu.name} (HDU {i}) ---\")\n",
    "    \n",
    "    if hasattr(hdu, 'columns') and hdu.columns is not None:\n",
    "        print(f\"Shape: {hdu.data.shape}\")\n",
    "        print(\"Columns:\")\n",
    "        for col_name in hdu.columns.names:\n",
    "            col = hdu.columns[col_name]\n",
    "            print(f\"  - {col_name}: format={col.format}, unit={col.unit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059d1e2-0862-4074-91d9-97959c85b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for each delta\n",
    "for name, hdul in deltas.items():\n",
    "    # Create the same subplot structure for each delta\n",
    "    f, axs = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "    axs[-1, -1].axis('off')\n",
    "    \n",
    "    # Set the main title for the entire figure\n",
    "    f.suptitle(f'Delta {name.upper()} Analysis', fontsize=16, y=1.02)\n",
    "\n",
    "    ### Stack Delta Plot\n",
    "    loglam = hdul['STACK_DELTAS'].data['LOGLAM'][:]\n",
    "    stack  = hdul['STACK_DELTAS'].data['STACK'][:]\n",
    "    cut = (stack != 0.) & (hdul['STACK_DELTAS'].data['WEIGHT'][:] > 0.)\n",
    "    loglam = loglam[cut]\n",
    "    stack  = stack[cut]\n",
    "    axs[0][0].plot(10.**loglam, stack, linewidth=1, color='blue')\n",
    "    axs[0][0].grid(alpha=0.3)\n",
    "    axs[0][0].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "    axs[0][0].set_ylabel(r'$\\mathrm{\\overline{Deltas}}$', fontsize=12)\n",
    "    axs[0][0].set_title('Stacked Deltas')\n",
    "\n",
    "    ### ETA Plot\n",
    "    loglam    = hdul['VAR_FUNC'].data['LOGLAM'][:]\n",
    "    eta       = hdul['VAR_FUNC'].data['ETA'][:]\n",
    "    nb_pixels = hdul['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "    cut = (nb_pixels > 0.) & (eta != 1.)\n",
    "    loglam = loglam[cut]\n",
    "    eta    = eta[cut]\n",
    "    axs[0][1].plot(10.**loglam, eta, linewidth=1, color='red')\n",
    "    axs[0][1].grid(alpha=0.3)\n",
    "    axs[0][1].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "    axs[0][1].set_ylabel(r'$\\eta$', fontsize=12)\n",
    "    axs[0][1].set_title('ETA')\n",
    "\n",
    "    ### VAR_LSS Plot\n",
    "    loglam    = hdul['VAR_FUNC'].data['LOGLAM'][:]\n",
    "    var_lss   = hdul['VAR_FUNC'].data['VAR_LSS'][:]\n",
    "    nb_pixels = hdul['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "    cut       = (nb_pixels > 0.) & (var_lss != 0.1)\n",
    "    loglam    = loglam[cut]\n",
    "    var_lss   = var_lss[cut]\n",
    "    axs[0][2].plot(10.**loglam, var_lss, linewidth=1, color='green')\n",
    "    axs[0][2].grid(alpha=0.3)\n",
    "    axs[0][2].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "    axs[0][2].set_ylabel(r'$\\sigma^{2}_{\\mathrm{LSS}}$', fontsize=12)\n",
    "    axs[0][2].set_title('VAR_LSS')\n",
    "\n",
    "    ### FUDGE Plot\n",
    "    loglam    = hdul['VAR_FUNC'].data['LOGLAM'][:]\n",
    "    fudge     = hdul['VAR_FUNC'].data['FUDGE'][:]\n",
    "    nb_pixels = hdul['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "    cut       = (nb_pixels > 0.) & (fudge != 1.e-7)\n",
    "    loglam    = loglam[cut]\n",
    "    fudge     = fudge[cut]\n",
    "    axs[1][0].plot(10.**loglam, fudge, linewidth=1, color='purple')\n",
    "    axs[1][0].grid(alpha=0.3)\n",
    "    axs[1][0].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "    axs[1][0].set_ylabel(r'$\\mathrm{Fudge}$', fontsize=12)\n",
    "    axs[1][0].set_title('FUDGE')\n",
    "\n",
    "    ### Mean Continuum Plot\n",
    "    loglam_rest = hdul['CONT'].data['LOGLAM_REST'][:]\n",
    "    mean_cont   = hdul['CONT'].data['MEAN_CONT'][:]\n",
    "    cut = (mean_cont != 0.) & (hdul['CONT'].data['WEIGHT'][:] > 0.)\n",
    "    loglam_rest = loglam_rest[cut]\n",
    "    mean_cont   = mean_cont[cut]\n",
    "    axs[1][1].plot(10.**loglam_rest, mean_cont, linewidth=1, color='orange')\n",
    "    axs[1][1].grid(alpha=0.3)\n",
    "    axs[1][1].set_xlabel(r'$\\lambda_{\\mathrm{R.F.}} \\, [\\AA]$', fontsize=12)\n",
    "    axs[1][1].set_ylabel(r'$\\mathrm{\\overline{Flux}}$', fontsize=12)\n",
    "    axs[1][1].set_title('Mean Continuum')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some info about each delta\n",
    "    print(f\"=== Delta {name.upper()} Summary ===\")\n",
    "    print(f\"Stacked Deltas range: {np.min(stack):.3f} to {np.max(stack):.3f}\")\n",
    "    print(f\"ETA range: {np.min(eta):.3f} to {np.max(eta):.3f}\")\n",
    "    print(f\"VAR_LSS range: {np.min(var_lss):.3f} to {np.max(var_lss):.3f}\")\n",
    "    print(f\"FUDGE range: {np.min(fudge):.3e} to {np.max(fudge):.3e}\")\n",
    "    print(f\"Mean Continuum range: {np.min(mean_cont):.3f} to {np.max(mean_cont):.3f}\")\n",
    "    print()\n",
    "\n",
    "# Close all FITS files when done\n",
    "for hdul in deltas.values():\n",
    "    hdul.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5495f06-2a41-4b80-a3db-57e47da202ce",
   "metadata": {},
   "source": [
    "## Comparison to Baseline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d3bca0-552f-4096-b877-6d918d3b9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot differences between deltas and deltasKP6 for all three types\n",
    "for name in deltas.keys():\n",
    "    if name in deltasKP6:  # Ensure the same delta exists in both dictionaries\n",
    "        # Create the same subplot structure for differences\n",
    "        f, axs = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "        axs[-1, -1].axis('off')\n",
    "        \n",
    "        # Set the main title for the entire figure\n",
    "        f.suptitle(f'Differences: Delta {name.upper()} (deltas - deltasKP6)', fontsize=16, y=1.02)\n",
    "\n",
    "        # Get both HDU lists\n",
    "        hdul_orig = deltas[name]\n",
    "        hdul_KP6 = deltasKP6[name]\n",
    "\n",
    "        ### Stack Delta Difference Plot\n",
    "        loglam_orig = hdul_orig['STACK_DELTAS'].data['LOGLAM'][:]\n",
    "        stack_orig = hdul_orig['STACK_DELTAS'].data['STACK'][:]\n",
    "        cut_orig = (stack_orig != 0.) & (hdul_orig['STACK_DELTAS'].data['WEIGHT'][:] > 0.)\n",
    "        \n",
    "        loglam_KP6 = hdul_KP6['STACK_DELTAS'].data['LOGLAM'][:]\n",
    "        stack_KP6 = hdul_KP6['STACK_DELTAS'].data['STACK'][:]\n",
    "        cut_KP6 = (stack_KP6 != 0.) & (hdul_KP6['STACK_DELTAS'].data['WEIGHT'][:] > 0.)\n",
    "        \n",
    "        # Find common wavelength range\n",
    "        common_loglam = np.intersect1d(loglam_orig[cut_orig], loglam_KP6[cut_KP6])\n",
    "        \n",
    "        if len(common_loglam) > 0:\n",
    "            # Get values at common wavelengths\n",
    "            orig_vals = stack_orig[cut_orig][np.isin(loglam_orig[cut_orig], common_loglam)]\n",
    "            KP6_vals = stack_KP6[cut_KP6][np.isin(loglam_KP6[cut_KP6], common_loglam)]\n",
    "            difference = orig_vals - KP6_vals\n",
    "            \n",
    "            axs[0][0].plot(10.**common_loglam, difference, linewidth=1, color='blue')\n",
    "            axs[0][0].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "            axs[0][0].grid(alpha=0.3)\n",
    "            axs[0][0].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "            axs[0][0].set_ylabel(r'$\\Delta \\mathrm{\\overline{Deltas}}$', fontsize=12)\n",
    "            axs[0][0].set_title('Stacked Deltas Difference')\n",
    "\n",
    "        ### ETA Difference Plot\n",
    "        loglam_orig = hdul_orig['VAR_FUNC'].data['LOGLAM'][:]\n",
    "        eta_orig = hdul_orig['VAR_FUNC'].data['ETA'][:]\n",
    "        nb_pixels_orig = hdul_orig['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "        cut_orig = (nb_pixels_orig > 0.) & (eta_orig != 1.)\n",
    "        \n",
    "        loglam_KP6 = hdul_KP6['VAR_FUNC'].data['LOGLAM'][:]\n",
    "        eta_KP6 = hdul_KP6['VAR_FUNC'].data['ETA'][:]\n",
    "        nb_pixels_KP6 = hdul_KP6['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "        cut_KP6 = (nb_pixels_KP6 > 0.) & (eta_KP6 != 1.)\n",
    "        \n",
    "        common_loglam = np.intersect1d(loglam_orig[cut_orig], loglam_KP6[cut_KP6])\n",
    "        \n",
    "        if len(common_loglam) > 0:\n",
    "            orig_vals = eta_orig[cut_orig][np.isin(loglam_orig[cut_orig], common_loglam)]\n",
    "            KP6_vals = eta_KP6[cut_KP6][np.isin(loglam_KP6[cut_KP6], common_loglam)]\n",
    "            difference = orig_vals - KP6_vals\n",
    "            \n",
    "            axs[0][1].plot(10.**common_loglam, difference, linewidth=1, color='red')\n",
    "            axs[0][1].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "            axs[0][1].grid(alpha=0.3)\n",
    "            axs[0][1].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "            axs[0][1].set_ylabel(r'$\\Delta \\eta$', fontsize=12)\n",
    "            axs[0][1].set_title('ETA Difference')\n",
    "\n",
    "        ### VAR_LSS Difference Plot\n",
    "        loglam_orig = hdul_orig['VAR_FUNC'].data['LOGLAM'][:]\n",
    "        var_lss_orig = hdul_orig['VAR_FUNC'].data['VAR_LSS'][:]\n",
    "        nb_pixels_orig = hdul_orig['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "        cut_orig = (nb_pixels_orig > 0.) & (var_lss_orig != 0.1)\n",
    "        \n",
    "        loglam_KP6 = hdul_KP6['VAR_FUNC'].data['LOGLAM'][:]\n",
    "        var_lss_KP6 = hdul_KP6['VAR_FUNC'].data['VAR_LSS'][:]\n",
    "        nb_pixels_KP6 = hdul_KP6['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "        cut_KP6 = (nb_pixels_KP6 > 0.) & (var_lss_KP6 != 0.1)\n",
    "        \n",
    "        common_loglam = np.intersect1d(loglam_orig[cut_orig], loglam_KP6[cut_KP6])\n",
    "        \n",
    "        if len(common_loglam) > 0:\n",
    "            orig_vals = var_lss_orig[cut_orig][np.isin(loglam_orig[cut_orig], common_loglam)]\n",
    "            KP6_vals = var_lss_KP6[cut_KP6][np.isin(loglam_KP6[cut_KP6], common_loglam)]\n",
    "            difference = orig_vals - KP6_vals\n",
    "            \n",
    "            axs[0][2].plot(10.**common_loglam, difference, linewidth=1, color='green')\n",
    "            axs[0][2].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "            axs[0][2].grid(alpha=0.3)\n",
    "            axs[0][2].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "            axs[0][2].set_ylabel(r'$\\Delta \\sigma^{2}_{\\mathrm{LSS}}$', fontsize=12)\n",
    "            axs[0][2].set_title('VAR_LSS Difference')\n",
    "\n",
    "        ### FUDGE Difference Plot\n",
    "        loglam_orig = hdul_orig['VAR_FUNC'].data['LOGLAM'][:]\n",
    "        fudge_orig = hdul_orig['VAR_FUNC'].data['FUDGE'][:]\n",
    "        nb_pixels_orig = hdul_orig['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "        cut_orig = (nb_pixels_orig > 0.) & (fudge_orig != 1.e-7)\n",
    "        \n",
    "        loglam_KP6 = hdul_KP6['VAR_FUNC'].data['LOGLAM'][:]\n",
    "        fudge_KP6 = hdul_KP6['VAR_FUNC'].data['FUDGE'][:]\n",
    "        nb_pixels_KP6 = hdul_KP6['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "        cut_KP6 = (nb_pixels_KP6 > 0.) & (fudge_KP6 != 1.e-7)\n",
    "        \n",
    "        common_loglam = np.intersect1d(loglam_orig[cut_orig], loglam_KP6[cut_KP6])\n",
    "        \n",
    "        if len(common_loglam) > 0:\n",
    "            orig_vals = fudge_orig[cut_orig][np.isin(loglam_orig[cut_orig], common_loglam)]\n",
    "            KP6_vals = fudge_KP6[cut_KP6][np.isin(loglam_KP6[cut_KP6], common_loglam)]\n",
    "            difference = orig_vals - KP6_vals\n",
    "            \n",
    "            axs[1][0].plot(10.**common_loglam, difference, linewidth=1, color='purple')\n",
    "            axs[1][0].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "            axs[1][0].grid(alpha=0.3)\n",
    "            axs[1][0].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "            axs[1][0].set_ylabel(r'$\\Delta \\mathrm{Fudge}$', fontsize=12)\n",
    "            axs[1][0].set_title('FUDGE Difference')\n",
    "\n",
    "        ### Mean Continuum Difference Plot\n",
    "        loglam_rest_orig = hdul_orig['CONT'].data['LOGLAM_REST'][:]\n",
    "        mean_cont_orig = hdul_orig['CONT'].data['MEAN_CONT'][:]\n",
    "        cut_orig = (mean_cont_orig != 0.) & (hdul_orig['CONT'].data['WEIGHT'][:] > 0.)\n",
    "        \n",
    "        loglam_rest_KP6 = hdul_KP6['CONT'].data['LOGLAM_REST'][:]\n",
    "        mean_cont_KP6 = hdul_KP6['CONT'].data['MEAN_CONT'][:]\n",
    "        cut_KP6 = (mean_cont_KP6 != 0.) & (hdul_KP6['CONT'].data['WEIGHT'][:] > 0.)\n",
    "        \n",
    "        common_loglam_rest = np.intersect1d(loglam_rest_orig[cut_orig], loglam_rest_KP6[cut_KP6])\n",
    "        \n",
    "        if len(common_loglam_rest) > 0:\n",
    "            orig_vals = mean_cont_orig[cut_orig][np.isin(loglam_rest_orig[cut_orig], common_loglam_rest)]\n",
    "            KP6_vals = mean_cont_KP6[cut_KP6][np.isin(loglam_rest_KP6[cut_KP6], common_loglam_rest)]\n",
    "            difference = orig_vals - KP6_vals\n",
    "            \n",
    "            axs[1][1].plot(10.**common_loglam_rest, difference, linewidth=1, color='orange')\n",
    "            axs[1][1].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "            axs[1][1].grid(alpha=0.3)\n",
    "            axs[1][1].set_xlabel(r'$\\lambda_{\\mathrm{R.F.}} \\, [\\AA]$', fontsize=12)\n",
    "            axs[1][1].set_ylabel(r'$\\Delta \\mathrm{\\overline{Flux}}$', fontsize=12)\n",
    "            axs[1][1].set_title('Mean Continuum Difference')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print statistics about the differences\n",
    "        print(f\"=== Delta {name.upper()} Difference Statistics ===\")\n",
    "        if len(common_loglam) > 0:\n",
    "            print(f\"Stacked Deltas diff - Mean: {np.mean(difference):.3e}, Std: {np.std(difference):.3e}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2375f7de-c047-4831-9185-7816e40ce8aa",
   "metadata": {},
   "source": [
    "# Re-running and Baseline Correlation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b02cb-4a5e-4b98-9034-fbe9b498c22c",
   "metadata": {},
   "source": [
    "## Exploring Re-running Correlation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfcd313-f036-4588-b0d7-a43902d85b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating dictionaries to store the data that we will use to plot the correlations\n",
    "\n",
    "correlation_data = {}\n",
    "grid_coordinates = {}\n",
    "\n",
    "# Processing all correlation functions from dictionary 'correlation_functions'\n",
    "for name, hdul in correlation_functions.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    \n",
    "    # Extracting correlation data, RP coordinate and RT coordinate with respect to line-of-sight (LOS)\n",
    "    corr_data = hdul['COR'].data['DA']\n",
    "    rp_data = hdul['COR'].data['RP']\n",
    "    rt_data = hdul['COR'].data['RT']\n",
    "    \n",
    "    # Determine grid size automatically\n",
    "    # For correlations with QSOs, we use fixed dimensions (100, 50). \n",
    "    # For correlations without QSOs, we obtain the dimensions automatically.\n",
    "    if name.startswith('qso'):\n",
    "        n_parallel = 100\n",
    "        n_transverse = 50\n",
    "        print(f\" Using fixed grid dimensions: ({n_parallel}, {n_transverse})\")\n",
    "    else:\n",
    "        n_parallel = int(np.sqrt(corr_data.size))\n",
    "        n_transverse = n_parallel\n",
    "        print(f\" Using automatic grid dimensions: ({n_parallel}, {n_transverse})\")\n",
    "    \n",
    "    # Reshape the correlation data and their coordinates data\n",
    "    correlation_reshaped = corr_data.reshape(n_parallel, n_transverse)\n",
    "    rp_reshaped = rp_data.reshape(n_parallel, n_transverse)\n",
    "    rt_reshaped = rt_data.reshape(n_parallel, n_transverse)\n",
    "    \n",
    "    # Storing in empty dictionaries\n",
    "    correlation_data[name] = {\n",
    "        'correlation': correlation_reshaped,\n",
    "        'original_data': corr_data\n",
    "    }\n",
    "    \n",
    "    grid_coordinates[name] = {\n",
    "        'rp': rp_reshaped,\n",
    "        'rt': rt_reshaped,\n",
    "        'original_rp': rp_data,\n",
    "        'original_rt': rt_data\n",
    "    }\n",
    "    \n",
    "    print(f\"  âœ“ Processed data: {correlation_reshaped.shape}\")\n",
    "    print(f\"  âœ“ Correlation rank: {np.min(correlation_reshaped):.3f} a {np.max(correlation_reshaped):.3f}\")\n",
    "    print()\n",
    "\n",
    "print(\"âœ… All data were processed and stored in dictionaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea5509-b60e-447f-ae4d-2724e6b3b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting correlation functions in bin space\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Correlation Functions\\n', fontsize=16, y=0.95)\n",
    "\n",
    "correlation_names = ['lyalya', 'lyalyb', 'qsolya', 'qsolyb']\n",
    "\n",
    "for idx, name in enumerate(correlation_names):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    # Getting data from dictionaries\n",
    "    corr = correlation_data[name]['correlation']\n",
    "    rp = grid_coordinates[name]['rp']\n",
    "    rt = grid_coordinates[name]['rt']\n",
    "\n",
    "    # Calculating the value of the correlation bins to plot\n",
    "    plot_data = (rt**2 + rp**2) * corr\n",
    "    \n",
    "    # Use imshow with extent instead\n",
    "    extent = [rt.min(), rt.max(), rp.min(), rp.max()]\n",
    "    mesh = ax.imshow(plot_data, extent=extent, cmap='RdYlBu', \n",
    "                    aspect='auto', origin='lower')\n",
    "    \n",
    "    cbar = plt.colorbar(mesh, ax=ax)\n",
    "    cbar.set_label(r'$r^2\\xi$($r_{\\parallel}$, $r_{\\perp}$)', fontsize=12)\n",
    "    \n",
    "    ax.set_xlabel('$r_{\\perp}$ [Mpc/h]', fontsize=12)\n",
    "    ax.set_ylabel('$r_{\\parallel}$ [Mpc/h]', fontsize=12)\n",
    "    \n",
    "    titles = {\n",
    "        'lyalya': r'$Ly\\alpha$ x $Ly\\alpha$',\n",
    "        'lyalyb': r'$Ly\\alpha$ x $Ly\\beta$', \n",
    "        'qsolya': r'$QSO$ x $Ly\\alpha$',\n",
    "        'qsolyb': r'$QSO$ x $Ly\\beta$'\n",
    "    }\n",
    "    ax.set_title(titles[name], fontsize=14)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58cacfc-03a8-45fc-8499-d4e8a146f9d9",
   "metadata": {},
   "source": [
    "## Exploring Baseline Correlation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e884b-1fa6-4d7b-be28-f56d31d7a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating dictionaries to store the data that we will use to plot the BASELINE correlations\n",
    "\n",
    "correlation_data_baseline = {}\n",
    "grid_coordinates_baseline = {}\n",
    "\n",
    "# Processing all correlation functions from dictionary 'correlation_functions_baseline'\n",
    "for name, hdul in correlation_functions_baseline.items():\n",
    "    print(f\"Processing BASELINE {name}...\")\n",
    "\n",
    "    # Extracting correlation data, RP coordinate and RT coordinate with respect to line-of-sight (LOS)\n",
    "    corr_data = hdul['COR'].data['DA']\n",
    "    rp_data = hdul['COR'].data['RP']\n",
    "    rt_data = hdul['COR'].data['RT']\n",
    "    \n",
    "    # Determine grid size automatically\n",
    "    # For correlations with QSOs, we use fixed dimensions (100, 50). \n",
    "    # For correlations without QSOs, we obtain the dimensions automatically.\n",
    "    if name.startswith('qso'):\n",
    "        n_parallel = 100\n",
    "        n_transverse = 50\n",
    "        print(f\" Using fixed grid dimensions: ({n_parallel}, {n_transverse})\")\n",
    "    else:\n",
    "        n_parallel = int(np.sqrt(corr_data.size))\n",
    "        n_transverse = n_parallel\n",
    "        print(f\" Using automatic grid dimensions: ({n_parallel}, {n_transverse})\")\n",
    "    \n",
    "    # Reshape the correlation data and their coordinates data\n",
    "    correlation_reshaped = corr_data.reshape(n_parallel, n_transverse)\n",
    "    rp_reshaped = rp_data.reshape(n_parallel, n_transverse)\n",
    "    rt_reshaped = rt_data.reshape(n_parallel, n_transverse)\n",
    "    \n",
    "    # Storing in BASELINE empty dictionaries\n",
    "    correlation_data_baseline[name] = {\n",
    "        'correlation': correlation_reshaped,\n",
    "        'original_data': corr_data\n",
    "    }\n",
    "    \n",
    "    grid_coordinates_baseline[name] = {\n",
    "        'rp': rp_reshaped,\n",
    "        'rt': rt_reshaped,\n",
    "        'original_rp': rp_data,\n",
    "        'original_rt': rt_data\n",
    "    }\n",
    "    \n",
    "    print(f\"  âœ“ Processed data: {correlation_reshaped.shape}\")\n",
    "    print(f\"  âœ“ Correlation rank: {np.min(correlation_reshaped):.3f} a {np.max(correlation_reshaped):.3f}\")\n",
    "    print()\n",
    "\n",
    "print(\"âœ… All BASELINE data were processed and stored in dictionaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18e263-8b90-471e-9629-38514b5f598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting BASELINE correlation functions in bin space\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Baseline Correlation Functions\\n', fontsize=16, y=0.95)\n",
    "\n",
    "correlation_names = ['lyalya', 'lyalyb', 'qsolya', 'qsolyb']\n",
    "\n",
    "for idx, name in enumerate(correlation_names):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Getting data from BASELINE dictionaries\n",
    "    corr = correlation_data_baseline[name]['correlation']\n",
    "    rp = grid_coordinates_baseline[name]['rp']\n",
    "    rt = grid_coordinates_baseline[name]['rt']\n",
    "    \n",
    "    # Calculating the value of the correlation bins to plot\n",
    "    plot_data = (rt**2 + rp**2) * corr\n",
    "    \n",
    "    # Use imshow with extent instead\n",
    "    extent = [rt.min(), rt.max(), rp.min(), rp.max()]\n",
    "    mesh = ax.imshow(plot_data, extent=extent, cmap='RdYlBu', \n",
    "                    aspect='auto', origin='lower')\n",
    "    \n",
    "    cbar = plt.colorbar(mesh, ax=ax)\n",
    "    cbar.set_label(r'$r^2\\xi$($r_{\\parallel}$, $r_{\\perp}$)', fontsize=12)\n",
    "    \n",
    "    ax.set_xlabel('$r_{\\perp}$ [Mpc/h]', fontsize=12)\n",
    "    ax.set_ylabel('$r_{\\parallel}$ [Mpc/h]', fontsize=12)\n",
    "    \n",
    "    titles = {\n",
    "        'lyalya': r'Baseline: $Ly\\alpha$ x $Ly\\alpha$',\n",
    "        'lyalyb': r'Baseline: $Ly\\alpha$ x $Ly\\beta$', \n",
    "        'qsolya': r'Baseline: $QSO$ x $Ly\\alpha$',\n",
    "        'qsolyb': r'Baseline: $QSO$ x $Ly\\beta$'\n",
    "    }\n",
    "    ax.set_title(titles[name], fontsize=14)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977413d-af97-4393-a7e9-7b06eb46d76b",
   "metadata": {},
   "source": [
    "## Comparisson to Baseline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d8812-28f2-4816-9983-10b5018bb5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of the DIFFERENCES between baseline and redo\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Difference: Redo - Baseline Correlation Functions\\n', fontsize=16, y=0.95)\n",
    "\n",
    "correlation_names = ['lyalya', 'lyalyb', 'qsolya', 'qsolyb']\n",
    "\n",
    "for idx, name in enumerate(correlation_names):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Getting data from BASELINE dictionaries\n",
    "    corr_baseline = correlation_data_baseline[name]['correlation']\n",
    "    rp_baseline = grid_coordinates_baseline[name]['rp']\n",
    "    rt_baseline = grid_coordinates_baseline[name]['rt']\n",
    "    \n",
    "    # Getting data from REDO dictionaries\n",
    "    corr_redo = correlation_data[name]['correlation']\n",
    "    rp_redo = grid_coordinates[name]['rp']\n",
    "    rt_redo = grid_coordinates[name]['rt']\n",
    "    \n",
    "    # Calculating the value of the correlation bins to plot\n",
    "\n",
    "    # difference = (rt_baseline**2 + rp_baseline**2) * (corr_redo - corr_baseline)\n",
    "    # or\n",
    "    # ratio = corr_redo/corr_baseline\n",
    "    \n",
    "    plot_data_baseline = (rt_baseline**2 + rp_baseline**2) * corr_baseline\n",
    "    plot_data_redo = (rt_redo**2 + rp_redo**2) * corr_redo\n",
    "    \n",
    "    # Calculating the difference: REDO - BASELINE\n",
    "    difference = plot_data_redo - plot_data_baseline\n",
    "    \n",
    "    # Use imshow with extent instead\n",
    "    extent = [rt_baseline.min(), rt_baseline.max(), rp_baseline.min(), rp_baseline.max()]\n",
    "    mesh = ax.imshow(difference, extent=extent, cmap='RdBu_r', \n",
    "                    aspect='auto', origin='lower')\n",
    "    \n",
    "    cbar = plt.colorbar(mesh, ax=ax)\n",
    "    cbar.set_label(r'$\\Delta~ r^2\\xi$($r_{\\parallel}$, $r_{\\perp}$)', fontsize=12)\n",
    "    \n",
    "    ax.set_xlabel('$r_{\\perp}$ [Mpc/h]', fontsize=12)\n",
    "    ax.set_ylabel('$r_{\\parallel}$ [Mpc/h]', fontsize=12)\n",
    "    \n",
    "    titles = {\n",
    "        'lyalya': r'$\\Delta$: $Ly\\alpha$ x $Ly\\alpha$',\n",
    "        'lyalyb': r'$\\Delta$: $Ly\\alpha$ x $Ly\\beta$', \n",
    "        'qsolya': r'$\\Delta$: $QSO$ x $Ly\\alpha$',\n",
    "        'qsolyb': r'$\\Delta$: $QSO$ x $Ly\\beta$'\n",
    "    }\n",
    "    ax.set_title(titles[name], fontsize=14)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ca152-1d84-44cb-8445-7cecd35dbcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
